{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0b9d5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e0224ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\SkinDiseaseProject\\\\skin_disease_predictor\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e393ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "801ac650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\SkinDiseaseProject\\\\skin_disease_predictor'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d11ab4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d47ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Metric\n",
    "class F1Score(Metric):\n",
    "    def __init__(self, name='f1_score', dtype=None):\n",
    "        super(F1Score, self).__init__(name=name, dtype=dtype)\n",
    "        self.true_positive = self.add_weight(name=\"tp\", initializer=\"zeros\")\n",
    "        self.false_positive = self.add_weight(name=\"fp\", initializer=\"zeros\")\n",
    "        self.false_negative = self.add_weight(name=\"fn\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.round(y_pred)  # Convert predictions to binary (0 or 1)\n",
    "        tp = tf.count_nonzero(y_true * y_pred)\n",
    "        fp = tf.count_nonzero((y_pred) * (y_true - 1))\n",
    "        fn = tf.count_nonzero((y_true) * (y_pred - 1))\n",
    "\n",
    "        self.true_positive.assign_add(tp)\n",
    "        self.false_positive.assign_add(fp)\n",
    "        self.false_negative.assign_add(fn)\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.true_positive / (self.true_positive + self.false_positive)\n",
    "        recall = self.true_positive / (self.true_positive + self.false_negative)\n",
    "        return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.true_positive.assign(0)\n",
    "        self.false_positive.assign(0)\n",
    "        self.false_negative.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5509d8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('artifacts/training/model.keras',custom_objects={\"F1Score\": F1Score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2856e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    " \n",
    "@dataclass(frozen=True)\n",
    "class EvaluationConfig:\n",
    "    path_of_model: Path\n",
    "    training_data: Path\n",
    "    all_params : dict\n",
    "    params_image_size: int\n",
    "    params_batch_size: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "137e06ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Acne_Prediction.constants import *\n",
    "from Acne_Prediction.utils.common import read_yaml,save_json, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c60fc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath = CONFIG_FILE_PATH,\n",
    "            params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_validation_config(self) -> EvaluationConfig:\n",
    "        eval_config = EvaluationConfig(\n",
    "            path_of_model= \"artifacts/training/model.keras\",\n",
    "            training_data = \"artifacts/data_ingestion/Dataset_new\",\n",
    "            all_params = self.params,\n",
    "            params_image_size = self.params.IMAGE_SIZE,\n",
    "            params_batch_size = self.params.BATCH_SIZE\n",
    "        )\n",
    "        return eval_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "393f1a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "    def __init__(self,config: EvaluationConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def _valid_generator(self):\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale = 1./255,\n",
    "            validation_split = 0.3\n",
    "        )\n",
    "    \n",
    "        dataflow_kwargs = dict(\n",
    "        target_size = self.config.params_image_size[:-1],\n",
    "        batch_size = self.config.params_batch_size,\n",
    "        class_mode = 'categorical'\n",
    "        )\n",
    "\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(**datagenerator_kwargs)\n",
    "\n",
    "        self._valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory = self.config.training_data,\n",
    "            subset = 'validation',\n",
    "            shuffle = False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_model(model_path: str) -> tf.keras.models.Model:\n",
    "        return tf.keras.models.load_model(model_path, custom_objects={\"F1Score\": F1Score})\n",
    "    \n",
    "    def evaluation(self):\n",
    "        self.model = self.load_model(self.config.path_of_model)\n",
    "        self._valid_generator()\n",
    "        self.score = model.evaluate(self._valid_generator)\n",
    "\n",
    "    def save_score(self):\n",
    "        scores = {\"loss\":self.score[0], \"accuracy\":self.score[1]}\n",
    "        save_json(path = Path(\"scores.json\"), data=scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b267344",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    val_config = config.get_validation_config()\n",
    "    evaluation = Evaluation(val_config)\n",
    "    evaluation.evaluation()\n",
    "    evaluation.save_score()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
